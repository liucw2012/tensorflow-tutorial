{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 保存计算两个变量和的模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Session\n",
      "[array([-0.8113182], dtype=float32), array([-0.8113182], dtype=float32), array([-1.6226364], dtype=float32)]\n",
      "call saver.save\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "tf.reset_default_graph()\n",
    "v1 = tf.Variable(tf.random_normal([1], stddev=1, seed=1),name=\"v1\")\n",
    "v2 = tf.Variable(tf.random_normal([1], stddev=1, seed=1),name=\"v2\")\n",
    "result = v1 + v2\n",
    "\n",
    "init_op = tf.global_variables_initializer()\n",
    "#位于 tf.train.Saver()之后的变量将不会被存储!\n",
    "saver = tf.train.Saver(max_to_keep=1)\n",
    "print(\"tf.Session\")\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init_op)\n",
    "    print(sess.run([v1,v2,result]))\n",
    "    print(\"call saver.save\")\n",
    "    saver.save(sess, \"./leo1/model.ckpt\")\n",
    "    saver.export_meta_graph(\"./leo-export_metagraph/model.ckpkt.meta.json\",as_text=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 加载保存了两个变量和的模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./leo1/model.ckpt\n",
      "[-1.6226364]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"./leo1/model.ckpt\")\n",
    "    print(sess.run(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> v2 [1]\n",
      "> v1 [1]\n"
     ]
    }
   ],
   "source": [
    "#看后面“从ckpt查看tensor name”\n",
    "import tensorflow as tf\n",
    "reader = tf.train.NewCheckpointReader(\"./leo1/model.ckpt\")\n",
    "global_variables = reader.get_variable_to_shape_map()\n",
    "for variable in global_variables:\n",
    "    print(\">\",variable,global_variables[variable])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 从ckpt查看tensor name        \n",
    "tf.Saver得到 model.ckpt.index和model.ckpt.data-**文件，其中保存了所有变量的取值。    \n",
    "其中model.ckpt.data文件通过SSTable格式存储的，可以大致理解为一个(key, value)列表。    \n",
    "TensorFlow提供了tf.train.NewCheckpointReader类来查看保存的变量信息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variable_name: v2\n",
      "global_varibles: [1]\n",
      "variable_name: v1\n",
      "global_varibles: [1]\n",
      "Value for variable v1 is [-0.8113182]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    " \n",
    "reader = tf.train.NewCheckpointReader('./leo1/model.ckpt')\n",
    " \n",
    "global_variables = reader.get_variable_to_shape_map()\n",
    "for variable_name in global_variables:\n",
    "    print(\"variable_name:\", variable_name)\n",
    "    print(\"global_varibles:\", global_variables[variable_name])\n",
    "    \n",
    "print(\"Value for variable v1 is\",reader.get_tensor(\"v1\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. 直接加载持久化的图。因为之前没有导出v3，所以这里会报错。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./leo1/model.ckpt\n",
      "v1 [-0.8113182]\n",
      "v2 [-0.8113182]\n"
     ]
    }
   ],
   "source": [
    "#恢复tensorflow图，也就是读取神经网络的结构，从而无需再次构建网络\n",
    "saver = tf.train.import_meta_graph(\"./leo1/model.ckpt.meta\")\n",
    "v3 = tf.Variable(tf.random_normal([1], stddev=1, seed=1))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"./leo1/model.ckpt\")\n",
    "    print(\"v1\", sess.run(v1))\n",
    "    print(\"v2\", sess.run(v2))\n",
    " #   print(\"v3\", sess.run(v3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. 变量重命名。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "v1 = tf.Variable(tf.constant(1.0, shape=[1]), name = \"other-v1\")\n",
    "v2 = tf.Variable(tf.constant(2.0, shape=[1]), name = \"other-v2\")\n",
    "saver = tf.train.Saver({\"v1\": v1, \"v2\": v2})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 读取placeholder和最终的输出结果\n",
    "```\n",
    "graph = tf.get_default_graph()    \n",
    "images_placeholder=graph.get_tensor_by_name('input_placeholder:0')\n",
    "labels_placeholder=graph.get_tensor_by_name('result_placeholder:0')\n",
    "logits=graph.get_tensor_by_name('softmax_linear/add:0')#最终输出结果的tensor\n",
    "```\n",
    "##### #恢复所有变量，包括权值\n",
    "```\n",
    "saver.restore(sess, tf.train.latest_checkpoint('D:/Work/python/GomokuPython-master/wuziqi/logs'))\n",
    "feed_dict=fill_feed_dict(_currentGame,images_placeholder,labels_placeholder)\n",
    "sessOutput=sess.run(logits, feed_dict=feed_dict)\n",
    "```    \n",
    "**以前版本的restore是需要指定哪个文件，而最新版本的restore需要指定目录，因为以前版本save结果只有一个文件，而现在有多个。如果碰到以下错误，\n",
    " Data loss: not an sstable (bad magic number): perhaps your file is in a different file\n",
    " 请检查你的restore函数传入的是文件名还是路径名。**\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5. 导出meta到summary，用tensorboard查看"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.platform import gfile\n",
    " \n",
    "graph = tf.get_default_graph()\n",
    "graphdef = graph.as_graph_def()\n",
    "_ = tf.train.import_meta_graph('meta的路径/xxxx.meta')\n",
    "summary = tf.summary.FileWriter('summary的路径', graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. 导出到meta graph json格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    " \n",
    "saver = tf.train.import_meta_graph(\"Saved_model/model.ckpt.meta\")\n",
    "saver.export_meta_graph(\"Saved_model/model.ckpt.meta.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.ckpt转换为pb模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.tools import inspect_checkpoint as chkp\n",
    "import tensorflow as tf\n",
    "\n",
    "saver = tf.train.import_meta_graph(\"./ade20k/model.ckpt-27150.meta\", clear_devices=True)\n",
    "\n",
    "#【敲黑板！】这里就是填写输出节点名称\n",
    "output_nodes = [\"xxx\"] \n",
    "\n",
    "with tf.Session(graph=tf.get_default_graph()) as sess:\n",
    "    input_graph_def = sess.graph.as_graph_def()\n",
    "    saver.restore(sess, \"./ade20k/model.ckpt-27150\")\n",
    "    output_graph_def = tf.graph_util.convert_variables_to_constants(sess,\n",
    "                                                                    input_graph_def,\n",
    "                                                                    output_nodes)\n",
    "    with open(\"frozen_model.pb\", \"wb\") as f:\n",
    "        f.write(output_graph_def.SerializeToString())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### new version ckpt to pb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import graph_util\n",
    "\n",
    "checkpoint = \"model.ckpt-xxx\"\n",
    "graph_file = \"xxx.pb\"\n",
    "\n",
    "\n",
    "def return_ops(candidate):\n",
    "    ops = []\n",
    "    if isinstance(candidate, (list, tuple)):\n",
    "        for x in candidate:\n",
    "            ops += return_ops(x)\n",
    "    else:\n",
    "        ops.append(candidate.op)\n",
    "\n",
    "    return ops\n",
    "\n",
    "\n",
    "def dump_graph():\n",
    "    with tf.Graph().as_default():\n",
    "        inputs = setup_input(dtype=tf.float32,\n",
    "                             shape=[None, 224, 224, 3],\n",
    "                             name='graph_input')\n",
    "\n",
    "        outputs = model_inference(inputs, 1000)\n",
    "\n",
    "        model_info = gen_info(inputs, outputs)\n",
    "        print(model_info)\n",
    "\n",
    "        saver = tf.train.Saver(tf.global_variables())\n",
    "        dest_node = return_ops(outputs)\n",
    "\n",
    "        with tf.Session() as sess:\n",
    "            saver.restore(sess, checkpoint)\n",
    "            cur_graphdef = sess.graph.as_graph_def()\n",
    "            output_graphdef = graph_util.convert_variables_to_constants(\n",
    "                sess, cur_graphdef, [n.name for n in dest_node])\n",
    "\n",
    "            with tf.gfile.GFile(graph_file, 'wb') as gf:\n",
    "                gf.write(output_graphdef.SerializeToString())\n",
    "\n",
    "            with open(graph_file + '.info', 'w') as info_f:\n",
    "                info_f.write(model_info)\n",
    "\n",
    "\n",
    "def setup_input(dtype, shape, name=None):\n",
    "    p_node = tf.Placeholder(dtype=dtype, shape=shape, name=name)\n",
    "    return p_node\n",
    "\n",
    "\n",
    "def gen_info(inp, o):\n",
    "    info_text = '[input tensor]: {0}\\n[input shape]: {1}\\n'.format(\n",
    "        inp.name, inp.get_shape())\n",
    "    print(\"outp\", o)\n",
    "    info_text += '[output tensor]: {0}\\n[output shape]: {1}\\n'.format(\n",
    "        o.name, o.get_shape())\n",
    "\n",
    "    return info_text\n",
    "\n",
    "\n",
    "def model_inference(images, num_classes):\n",
    "    with tf.variable_scope('xxx'):\n",
    "        logits = tf.xxx\n",
    "    return logits\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    dump_graph()\n",
    "    print('dump finish!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "saver_max_acc: 0\n",
      "racc: 0.292 0\n",
      "saver.save 0.292 0\n",
      "racc: 0.4474 0.292\n",
      "saver.save 0.4474 0.292\n",
      "racc: 0.5245 0.4474\n",
      "saver.save 0.5245 0.4474\n",
      "racc: 0.4374 0.5245\n",
      "racc: 0.5696 0.5245\n",
      "saver.save 0.5696 0.5245\n",
      "racc: 0.6433 0.5696\n",
      "saver.save 0.6433 0.5696\n",
      "racc: 0.6661 0.6433\n",
      "saver.save 0.6661 0.6433\n",
      "racc: 0.6254 0.6661\n",
      "racc: 0.6799 0.6661\n",
      "saver.save 0.6799 0.6661\n",
      "racc: 0.6836 0.6799\n",
      "10:0.6836\n",
      "saver.save 0.6836 0.6799\n",
      "racc: 0.7343 0.6836\n",
      "saver.save 0.7343 0.6836\n",
      "racc: 0.6642 0.7343\n",
      "racc: 0.717 0.7343\n",
      "racc: 0.6161 0.7343\n",
      "racc: 0.6812 0.7343\n",
      "racc: 0.709 0.7343\n",
      "racc: 0.76 0.7343\n",
      "saver.save 0.76 0.7343\n",
      "racc: 0.8001 0.76\n",
      "saver.save 0.8001 0.76\n",
      "racc: 0.7817 0.8001\n",
      "racc: 0.7748 0.8001\n",
      "20:0.7748\n",
      "racc: 0.8196 0.8001\n",
      "saver.save 0.8196 0.8001\n",
      "racc: 0.8108 0.8196\n",
      "racc: 0.8284 0.8196\n",
      "saver.save 0.8284 0.8196\n",
      "racc: 0.8512 0.8284\n",
      "saver.save 0.8512 0.8284\n",
      "racc: 0.8527 0.8512\n",
      "saver.save 0.8527 0.8512\n",
      "racc: 0.8544 0.8527\n",
      "saver.save 0.8544 0.8527\n",
      "racc: 0.852 0.8544\n",
      "racc: 0.8561 0.8544\n",
      "saver.save 0.8561 0.8544\n",
      "racc: 0.8392 0.8561\n",
      "racc: 0.8469 0.8561\n",
      "30:0.8469\n",
      "racc: 0.8699 0.8561\n",
      "saver.save 0.8699 0.8561\n",
      "racc: 0.8668 0.8699\n",
      "racc: 0.8575 0.8699\n",
      "racc: 0.7643 0.8699\n",
      "racc: 0.7473 0.8699\n",
      "racc: 0.7736 0.8699\n",
      "racc: 0.7899 0.8699\n",
      "racc: 0.7959 0.8699\n",
      "racc: 0.8386 0.8699\n",
      "racc: 0.8734 0.8699\n",
      "40:0.8734\n",
      "saver.save 0.8734 0.8699\n",
      "racc: 0.8802 0.8734\n",
      "saver.save 0.8802 0.8734\n",
      "racc: 0.8565 0.8802\n",
      "racc: 0.8422 0.8802\n",
      "racc: 0.8485 0.8802\n",
      "racc: 0.8672 0.8802\n",
      "racc: 0.8584 0.8802\n",
      "racc: 0.8342 0.8802\n",
      "racc: 0.8517 0.8802\n",
      "racc: 0.8848 0.8802\n",
      "saver.save 0.8848 0.8802\n",
      "racc: 0.8705 0.8848\n",
      "50:0.8705\n",
      "racc: 0.8901 0.8848\n",
      "saver.save 0.8901 0.8848\n",
      "racc: 0.8812 0.8901\n",
      "racc: 0.8623 0.8901\n",
      "racc: 0.8561 0.8901\n",
      "racc: 0.8824 0.8901\n",
      "racc: 0.8853 0.8901\n",
      "racc: 0.8776 0.8901\n",
      "racc: 0.8791 0.8901\n",
      "racc: 0.8709 0.8901\n",
      "racc: 0.8384 0.8901\n",
      "60:0.8384\n",
      "racc: 0.8876 0.8901\n",
      "racc: 0.872 0.8901\n",
      "racc: 0.8863 0.8901\n",
      "racc: 0.8893 0.8901\n",
      "racc: 0.8834 0.8901\n",
      "racc: 0.883 0.8901\n",
      "racc: 0.8855 0.8901\n",
      "racc: 0.8845 0.8901\n",
      "racc: 0.8915 0.8901\n",
      "saver.save 0.8915 0.8901\n",
      "racc: 0.8646 0.8915\n",
      "70:0.8646\n",
      "racc: 0.886 0.8915\n",
      "racc: 0.8802 0.8915\n",
      "racc: 0.8811 0.8915\n",
      "racc: 0.8764 0.8915\n",
      "racc: 0.8965 0.8915\n",
      "saver.save 0.8965 0.8915\n",
      "racc: 0.897 0.8965\n",
      "saver.save 0.897 0.8965\n",
      "racc: 0.8899 0.897\n",
      "racc: 0.8807 0.897\n",
      "racc: 0.8803 0.897\n",
      "racc: 0.8639 0.897\n",
      "80:0.8639\n",
      "racc: 0.8673 0.897\n",
      "racc: 0.8703 0.897\n",
      "racc: 0.87 0.897\n",
      "racc: 0.8959 0.897\n",
      "racc: 0.8835 0.897\n",
      "racc: 0.8922 0.897\n",
      "racc: 0.8895 0.897\n",
      "racc: 0.8804 0.897\n",
      "racc: 0.8757 0.897\n",
      "racc: 0.8897 0.897\n",
      "90:0.8897\n",
      "racc: 0.8849 0.897\n",
      "racc: 0.8321 0.897\n",
      "racc: 0.8137 0.897\n",
      "racc: 0.8469 0.897\n",
      "racc: 0.8929 0.897\n",
      "racc: 0.8926 0.897\n",
      "racc: 0.8938 0.897\n",
      "racc: 0.8887 0.897\n",
      "racc: 0.8754 0.897\n",
      "racc: 0.8643 0.897\n",
      "100:0.8643\n",
      "70.993102\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "\n",
    "import tensorflow as tf\n",
    "import time\n",
    "\n",
    "time.clock()\n",
    "\n",
    "x = tf.placeholder(tf.float32 ,[None, 784])\n",
    "W = tf.Variable(tf.zeros([784,10]))\n",
    "b = tf.Variable(tf.zeros([10]))\n",
    "y = tf.nn.softmax(tf.matmul(x,W) + b)\n",
    "\n",
    "# 为了计算交叉熵，我们需要添加一个新的占位符用于输入正确值。\n",
    "y_ = tf.placeholder(tf.float32, [None,10])\n",
    "cross_entropy = -tf.reduce_sum(y_*tf.log(y))\n",
    "# 在此，我们要求TF使用梯度下降算法，并以0.01的学习速率最小化交叉熵。\n",
    "train_step = tf.train.GradientDescentOptimizer(0.01).minimize(cross_entropy)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "#创建Saver节点，并设置自动保存最近n=1次模型\n",
    "saver = tf.train.Saver(max_to_keep=1)\n",
    "saver_max_acc = 0 \n",
    "print(\"saver_max_acc:\",saver_max_acc)\n",
    "for i in range(100):\n",
    "    batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "    sess.run(train_step, feed_dict={x: batch_xs, y_:batch_ys})\n",
    "    correct_prediction = tf.equal(tf.argmax(y,1), tf.arg_max(y_, 1))\n",
    "    #准确率应该用测试数据进行评估\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction,\"float\"))\n",
    "    racc = sess.run(accuracy,feed_dict={x: mnist.test.images, y_:mnist.test.labels})\n",
    "    print(\"racc:\",racc,saver_max_acc)\n",
    "    if (i+1)%10 == 0:\n",
    "        print('{0:0>2d}:{1:.4f}'.format((i+1),accuracy.eval(session=sess, feed_dict={x: mnist.test.images, y_: mnist.test.labels})))\n",
    "    # 添加判断语句，选择保存精度最高的模型\n",
    "    if racc > saver_max_acc:\n",
    "        print(\"saver.save\",racc,saver_max_acc)\n",
    "        saver.save(sess,'leo/mnist.ckpt',global_step=i+1)\n",
    "        saver_max_acc = racc\n",
    "sess.close()\n",
    "print(time.clock())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 详解TensorFlow查看ckpt中变量的几种方法\n",
    "\n",
    "查看TensorFlow中checkpoint内变量的几种方法：    \n",
    "\n",
    "查看ckpt中变量的方法有三种：    \n",
    "     \n",
    "在有model的情况下，使用tf.train.Saver进行restore    \n",
    "使用tf.train.NewCheckpointReader直接读取ckpt文件，这种方法不需要model。    \n",
    "使用tools里的freeze_graph来读取ckpt    \n",
    "注意：    \n",
    "\n",
    "如果模型保存为.ckpt的文件，则使用该文件就可以查看.ckpt文件里的变量。ckpt路径为 model.ckpt    \n",
    "如果模型保存为.ckpt-xxx-data (图结构)、.ckpt-xxx.index (参数名)、.ckpt-xxx-meta (参数值)文件，则需要同时拥有这三个文件才行。 并且ckpt的路径为 model.ckpt-xxx    \n",
    "1. 基于model来读取ckpt文件里的变量    \n",
    "\n",
    "首先建立model    \n",
    "从ckpt中恢复变量    \n",
    "```\n",
    "with tf.Graph().as_default() as g:\n",
    "\n",
    "  #建立model\n",
    "\n",
    "  images, labels = cifar10.inputs(eval_data=eval_data)\n",
    "\n",
    "  logits = cifar10.inference(images)\n",
    "\n",
    "  top_k_op = tf.nn.in_top_k(logits, labels, 1)\n",
    "\n",
    "  #从ckpt中恢复变量\n",
    "\n",
    "  sess = tf.Session()\n",
    "\n",
    "  saver = tf.train.Saver() #saver = tf.train.Saver(...variables...) # 恢复部分变量时，只需要在Saver里指定要恢复的变量\n",
    "\n",
    "  save_path = 'ckpt的路径'\n",
    "\n",
    "  saver.restore(sess, save_path) # 从ckpt中恢复变量\n",
    "```\n",
    "注意：基于model来读取ckpt中变量时，model和ckpt必须匹配。\n",
    "\n",
    "1. 使用tf.train.NewCheckpointReader直接读取ckpt文件里的变量，使用tools.inspect_checkpoint里的print_tensors_in_checkpoint_file函数打印ckpt里的东西    \n",
    "```\n",
    "#使用NewCheckpointReader来读取ckpt里的变量    \n",
    "\n",
    "from tensorflow.python import pywrap_tensorflow\n",
    "\n",
    "checkpoint_path = os.path.join(model_dir, \"model.ckpt\")\n",
    "\n",
    "reader = pywrap_tensorflow.NewCheckpointReader(checkpoint_path) #tf.train.NewCheckpointReader\n",
    "\n",
    "var_to_shape_map = reader.get_variable_to_shape_map()\n",
    "\n",
    "for key in var_to_shape_map:\n",
    "\n",
    "  print(\"tensor_name: \", key)\n",
    "\n",
    "  #print(reader.get_tensor(key))\n",
    "#使用print_tensors_in_checkpoint_file打印ckpt里的内容\n",
    "\n",
    "from tensorflow.python.tools.inspect_checkpoint import print_tensors_in_checkpoint_file\n",
    "\n",
    "\n",
    "print_tensors_in_checkpoint_file(file_name, #ckpt文件名字\n",
    "\n",
    "                 tensor_name, # 如果为None,则默认为ckpt里的所有变量\n",
    "\n",
    "                 all_tensors, # bool 是否打印所有的tensor，这里打印出的是tensor的值，一般不推荐这里设置为False\n",
    "\n",
    "                 all_tensor_names) # bool 是否打印所有的tensor的name\n",
    "```               \n",
    "\n",
    "#上面的打印ckpt的内部使用的是pywrap_tensorflow.NewCheckpointReader所以，掌握NewCheckpointReader才是王道\n",
    "\n",
    "1. 使用tools里的freeze_graph来读取ckpt\n",
    "```\n",
    "from tensorflow.python.tools import freeze_graph\n",
    "\n",
    "\n",
    "freeze_graph(input_graph, #=some_graph_def.pb\n",
    "\n",
    "       input_saver,\n",
    "\n",
    "       input_binary,\n",
    "\n",
    "       input_checkpoint, #=model.ckpt\n",
    "\n",
    "       output_node_names, #=softmax\n",
    "\n",
    "       restore_op_name,\n",
    "\n",
    "       filename_tensor_name,\n",
    "\n",
    "       output_graph, #='./tmp/frozen_graph.pb'\n",
    "\n",
    "       clear_devices,\n",
    "\n",
    "       initializer_nodes,\n",
    "\n",
    "       variable_names_whitelist='',\n",
    "\n",
    "       variable_names_blacklist='',\n",
    "\n",
    "       input_meta_graph=None,\n",
    "\n",
    "       input_saved_model_dir=None,\n",
    "\n",
    "       saved_model_tags='serve',\n",
    "\n",
    "       checkpoint_version=2)\n",
    "\n",
    "#freeze_graph_test.py讲述了怎么使用freeze_grapg。\n",
    "使用freeze_graph可以将图和ckpt进行合并\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
