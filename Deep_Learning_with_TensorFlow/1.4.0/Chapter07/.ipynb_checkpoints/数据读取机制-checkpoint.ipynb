{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "十图详解tensorflow数据读取机制\n",
    "何之源\n",
    "\n",
    "深度学习（Deep Learning） 话题的优秀回答者\n",
    "\n",
    "在学习tensorflow的过程中，有很多小伙伴反映读取数据这一块很难理解。确实这一块官方的教程比较简略，网上也找不到什么合适的学习材料。今天这篇文章就以图片的形式，用最简单的语言，为大家详细解释一下tensorflow的数据读取机制，文章的最后还会给出实战代码以供参考。\n",
    "\n",
    "一、tensorflow读取机制图解\n",
    "首先需要思考的一个问题是，什么是数据读取？以图像数据为例，读取数据的过程可以用下图来表示：\n",
    "\n",
    "\n",
    "假设我们的硬盘中有一个图片数据集0001.jpg，0002.jpg，0003.jpg……我们只需要把它们读取到内存中，然后提供给GPU或是CPU进行计算就可以了。这听起来很容易，但事实远没有那么简单。事实上，我们必须要把数据先读入后才能进行计算，假设读入用时0.1s，计算用时0.9s，那么就意味着每过1s，GPU都会有0.1s无事可做，这就大大降低了运算的效率。\n",
    "如何解决这个问题？方法就是将读入数据和计算分别放在两个线程中，将数据读入内存的一个队列，如下图所示：\n",
    "\n",
    "\n",
    "读取线程源源不断地将文件系统中的图片读入到一个内存的队列中，而负责计算的是另一个线程，计算需要数据时，直接从内存队列中取就可以了。这样就可以解决GPU因为IO而空闲的问题！\n",
    "而在tensorflow中，为了方便管理，在内存队列前又添加了一层所谓的“文件名队列”。\n",
    "\n",
    "为什么要添加这一层文件名队列？我们首先得了解机器学习中的一个概念：epoch。对于一个数据集来讲，运行一个epoch就是将这个数据集中的图片全部计算一遍。如一个数据集中有三张图片A.jpg、B.jpg、C.jpg，那么跑一个epoch就是指对A、B、C三张图片都计算了一遍。两个epoch就是指先对A、B、C各计算一遍，然后再全部计算一遍，也就是说每张图片都计算了两遍。\n",
    "\n",
    "tensorflow使用文件名队列+内存队列双队列的形式读入文件，可以很好地管理epoch。下面我们用图片的形式来说明这个机制的运行方式。如下图，还是以数据集A.jpg, B.jpg, C.jpg为例，假定我们要跑一个epoch，那么我们就在文件名队列中把A、B、C各放入一次，并在之后标注队列结束。\n",
    "\n",
    "\n",
    "程序运行后，内存队列首先读入A（此时A从文件名队列中出队）：\n",
    "\n",
    "再依次读入B和C：\n",
    "\n",
    "\n",
    "\n",
    "此时，如果再尝试读入，系统由于检测到了“结束”，就会自动抛出一个异常（OutOfRange）。外部捕捉到这个异常后就可以结束程序了。这就是tensorflow中读取数据的基本机制。如果我们要跑2个epoch而不是1个epoch，那只要在文件名队列中将A、B、C依次放入两次再标记结束就可以了。\n",
    "二、tensorflow读取数据机制的对应函数\n",
    "如何在tensorflow中创建上述的两个队列呢？\n",
    "\n",
    "对于文件名队列，我们使用tf.train.string_input_producer函数。这个函数需要传入一个文件名list，系统会自动将它转为一个文件名队列。\n",
    "\n",
    "此外tf.train.string_input_producer还有两个重要的参数，一个是num_epochs，它就是我们上文中提到的epoch数。另外一个就是shuffle，shuffle是指在一个epoch内文件的顺序是否被打乱。若设置shuffle=False，如下图，每个epoch内，数据还是按照A、B、C的顺序进入文件名队列，这个顺序不会改变：\n",
    "\n",
    "\n",
    "如果设置shuffle=True，那么在一个epoch内，数据的前后顺序就会被打乱，如下图所示：\n",
    "\n",
    "\n",
    "在tensorflow中，内存队列不需要我们自己建立，我们只需要使用reader对象从文件名队列中读取数据就可以了，具体实现可以参考下面的实战代码。\n",
    "除了tf.train.string_input_producer外，我们还要额外介绍一个函数：tf.train.start_queue_runners。初学者会经常在代码中看到这个函数，但往往很难理解它的用处，在这里，有了上面的铺垫后，我们就可以解释这个函数的作用了。\n",
    "\n",
    "**在我们使用tf.train.string_input_producer创建文件名队列后，整个系统其实还是处于“停滞状态”的，** 也就是说，我们文件名并没有真正被加入到队列中（如下图所示）。此时如果我们开始计算，因为内存队列中什么也没有，计算单元就会一直等待，导致整个系统被阻塞。\n",
    "\n",
    "\n",
    "**而使用tf.train.start_queue_runners之后，才会启动填充队列的线程，这时系统就不再“停滞”** 此后计算单元就可以拿到数据并进行计算，整个程序也就跑起来了，这就是函数tf.train.start_queue_runners的用处。\n",
    "\n",
    "\n",
    "三、实战代码\n",
    "我们用一个具体的例子感受tensorflow中的数据读取。如图，假设我们在当前文件夹中已经有A.jpg、B.jpg、C.jpg三张图片，我们希望读取这三张图片5个epoch并且把读取的结果重新存到read文件夹中。\n",
    "\n",
    "\n",
    "对应的代码如下：\n",
    "```\n",
    "import tensorflow as tf \n",
    "with tf.Session() as sess:\n",
    "    # 我们要读三幅图片A.jpg, B.jpg, C.jpg\n",
    "    filename = ['A.jpg', 'B.jpg', 'C.jpg']\n",
    "    # string_input_producer会产生一个文件名队列\n",
    "    filename_queue = tf.train.string_input_producer(filename, shuffle=False, num_epochs=5)\n",
    "    # reader从文件名队列中读数据。对应的方法是reader.read\n",
    "    reader = tf.WholeFileReader()\n",
    "    key, value = reader.read(filename_queue)\n",
    "    # tf.train.string_input_producer定义了一个epoch变量，要对它进行初始化\n",
    "    tf.local_variables_initializer().run()\n",
    "    # 使用start_queue_runners之后，才会开始填充队列\n",
    "    threads = tf.train.start_queue_runners(sess=sess)\n",
    "    i = 0\n",
    "    while True:\n",
    "        i += 1\n",
    "        # 获取图片数据并保存\n",
    "        image_data = sess.run(value)\n",
    "        with open('read/test_%d.jpg' % i, 'wb') as f:\n",
    "            f.write(image_data)\n",
    "```  \n",
    "我们这里使用filename_queue = tf.train.string_input_producer(filename, shuffle=False, num_epochs=5)建立了一个会跑5个epoch的文件名队列。并使用reader读取，reader每次读取一张图片并保存。\n",
    "\n",
    "运行代码后，我们得到就可以看到read文件夹中的图片，正好是按顺序的5个epoch：\n",
    "\n",
    "\n",
    "如果我们设置filename_queue = tf.train.string_input_producer(filename, shuffle=False, num_epochs=5)中的shuffle=True，那么在每个epoch内图像就会被打乱，如图所示：\n",
    "\n",
    "我们这里只是用三张图片举例，实际应用中一个数据集肯定不止3张图片，不过涉及到的原理都是共通的。\n",
    "四、总结\n",
    "这篇文章主要用图解的方式详细介绍了tensorflow读取数据的机制，最后还给出了对应的实战代码，希望能够给大家学习tensorflow带来一些实质性的帮助。如果各位小伙伴还有什么疑问，欢迎评论或私信告诉我，谢谢~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "from io import BytesIO\n",
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "# Helper libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# 加载tfrecords文件\n",
    "object_datasets = tf.data.TFRecordDataset(\"C:/Users/53111/Desktop/voc2007/JPEGImages/train.tfrecord\")\n",
    "\n",
    "# 创建一个描述功能的字典，就是你在数据里都加了什么类型的字段\n",
    "# FixedLenFeature代表固定长度字段里边的中括号是必须有的\n",
    "# VarLenFeature代表可变长度的字段里边只要指定类型就好\n",
    "\n",
    "object_feature = {\n",
    "\t'image/height': tf.io.FixedLenFeature([], tf.int64),\n",
    "\t'image/width':  tf.io.FixedLenFeature([], tf.int64),\n",
    "    'image/filename': tf.io.FixedLenFeature([], tf.string),\n",
    "    'image/source_id': tf.io.FixedLenFeature([], tf.string),\n",
    "    'image/encoded': tf.io.FixedLenFeature([], tf.string),\n",
    "    'image/format': tf.io.FixedLenFeature([], tf.string),\n",
    "    'image/object/bbox/xmin': tf.io.VarLenFeature(tf.float32),\n",
    "    'image/object/bbox/xmax': tf.io.VarLenFeature(tf.float32),\n",
    "    'image/object/bbox/ymin': tf.io.VarLenFeature(tf.float32),\n",
    "    'image/object/bbox/ymax': tf.io.VarLenFeature(tf.float32),\n",
    "    'image/object/class/text': tf.io.VarLenFeature(tf.string),\n",
    "    'image/object/class/label': tf.io.VarLenFeature(tf.int64),\n",
    "}\n",
    "\n",
    "# 划重点，这个映射函数是必须要有的\n",
    "# 这里的exam_proto不用自己传，函数里的第二个参数是上面定义的功能字典\n",
    "# 映射函数，用于解析一条example\n",
    "def _parse_function (exam_proto): \n",
    "    return tf.io.parse_single_example (exam_proto, object_feature)\n",
    "\n",
    "# 这里把解析函数传进来就好了  \n",
    "x = object_datasets.map(_parse_function)\n",
    "\n",
    "\n",
    "# 这里通过for循环读取每条数据，\n",
    "# 这里的重点是用plt显示二进制图片\n",
    "# 其他的可以自行读取\n",
    "\n",
    "for i in x:\n",
    "\tprint(i['image/height'])\n",
    "\ti_raw = i['image/encoded'].numpy()\n",
    "\tplt.figure(\"Image\") # 图像窗口名称\n",
    "\tplt.imshow(plt.imread(BytesIO(i_raw)))\n",
    "\tplt.axis('on') # 关掉坐标轴为 off\n",
    "\tplt.title('image') # 图像题目\n",
    "\tplt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 将CSV文件转化为TFRecords文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    " \n",
    "train_frame = pd.read_csv(\"train.csv\")\n",
    "print(train_frame.head())\n",
    "train_labels_frame = train_frame.pop(item=\"label\")\n",
    "train_values = train_frame.values\n",
    "train_labels = train_labels_frame.values\n",
    "print(\"values shape: \", train_values.shape)\n",
    "print(\"labels shape:\", train_labels.shape)\n",
    " \n",
    "writer = tf.python_io.TFRecordWriter(\"csv_train.tfrecords\")\n",
    " \n",
    "for i in range(train_values.shape[0]):\n",
    "    image_raw = train_values[i].tostring()\n",
    "    example = tf.train.Example(\n",
    "        features=tf.train.Features(\n",
    "            feature={\n",
    "                \"image_raw\": tf.train.Feature(bytes_list=tf.train.BytesList(value=[image_raw])),\n",
    "                \"label\": tf.train.Feature(int64_list=tf.train.Int64List(value=[train_labels[i]]))\n",
    "            }\n",
    "        )\n",
    "    )\n",
    "    writer.write(record=example.SerializeToString())\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 将png转化为TFRecord文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-b2f7a59ef26e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_label_from_filename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    " \n",
    "def get_label_from_filename(filename):\n",
    "    return 1\n",
    " \n",
    "filenames = tf.train.match_filenames_once('.\\data\\*.png')\n",
    " \n",
    "writer = tf.python_io.TFRecordWriter('png_train.tfrecords')\n",
    " \n",
    "for filename in filenames:\n",
    "    img=mpimg.imread(filename)\n",
    "    print(\"{} shape is {}\".format(filename, img.shape))\n",
    "    img_raw = img.tostring()\n",
    "    label = get_label_from_filename(filename)\n",
    "    example = tf.train.Example(\n",
    "        features=tf.train.Features(\n",
    "            feature={\n",
    "                \"image_raw\": tf.train.Feature(bytes_list=tf.train.BytesList(value=[image_raw])),\n",
    "                \"label\": tf.train.Feature(int64_list=tf.train.Int64List(value=[label]))\n",
    "            }\n",
    "        )\n",
    "    )\n",
    "    writer.write(record=example.SerializeToString())\n",
    " \n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
